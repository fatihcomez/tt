{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **TikTok Project**\n",
    "**Course 2 - Get Started with Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJCatj3xzrQZ"
   },
   "source": [
    "Welcome to the TikTok Project!\n",
    "\n",
    "You have just started as a data professional at TikTok.\n",
    "\n",
    "The team is still in the early stages of the project. You have received notice that TikTok's leadership team has approved the project proposal. To gain clear insights to prepare for a claims classification model, TikTok's provided data must be examined to begin the process of exploratory data analysis (EDA).\n",
    "\n",
    "A notebook was structured and prepared to help you in this project. Please complete the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# **Course 2 End-of-course project: Inspect and analyze data**\n",
    "\n",
    "In this activity, you will examine data provided and prepare it for analysis.\n",
    "<br/>\n",
    "\n",
    "**The purpose** of this project is to investigate and understand the data provided. This activity will:\n",
    "\n",
    "1.   Acquaint you with the data\n",
    "\n",
    "2.   Compile summary information about the data\n",
    "\n",
    "3.   Begin the process of EDA and reveal insights contained in the data\n",
    "\n",
    "4.   Prepare you for more in-depth EDA, hypothesis testing, and statistical analysis\n",
    "\n",
    "**The goal** is to construct a dataframe in Python, perform a cursory inspection of the provided dataset, and inform TikTok data team members of your findings.\n",
    "<br/>\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Understand the situation\n",
    "* How can you best prepare to understand and organize the provided TikTok information?\n",
    "\n",
    "**Part 2:** Understand the data\n",
    "\n",
    "* Create a pandas dataframe for data learning and future exploratory data analysis (EDA) and statistical activities\n",
    "\n",
    "* Compile summary information about the data to inform next steps\n",
    "\n",
    "**Part 3:** Understand the variables\n",
    "\n",
    "* Use insights from your examination of the summary data to guide deeper investigation into variables\n",
    "\n",
    "<br/>\n",
    "\n",
    "To complete the activity, follow the instructions and answer the questions below. Then, you will us your responses to these questions and the questions included in the Course 2 PACE Strategy Document to create an executive summary.\n",
    "\n",
    "Be sure to complete this activity before moving on to Course 3. You can assess your work by comparing the results to a completed exemplar after completing the end-of-course project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjFGokxv2pc5"
   },
   "source": [
    "# **Identify data types and compile summary information**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRUYfzCb4vop"
   },
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute.\n",
    "\n",
    "# **PACE stages**\n",
    "\n",
    "<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "   *        [Plan](#scrollTo=psz51YkZVwtN&line=3&uniqifier=1)\n",
    "   *        [Analyze](#scrollTo=mA7Mz_SnI8km&line=4&uniqifier=1)\n",
    "   *        [Construct](#scrollTo=Lca9c8XON8lc&line=2&uniqifier=1)\n",
    "   *        [Execute](#scrollTo=401PgchTPr4E&line=2&uniqifier=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRHb2QQWj99m"
   },
   "source": [
    "<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "\n",
    "## **PACE: Plan**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document and those below to craft your response:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TD5rUDqtNoiH"
   },
   "source": [
    "### **Task 1. Understand the situation**\n",
    "\n",
    "*   How can you best prepare to understand and organize the provided information?\n",
    "\n",
    "\n",
    "*Begin by exploring your dataset and consider reviewing the Data Dictionary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9WkTfMU4_mB"
   },
   "source": [
    "Start with getting familiar with the data files, how they are organized on the disk, folders, etc. Then, try identify collection timespan, if they are 2nd or 3rd sources, how they were collected and if they ara anonymized. I would also try to understand if I should expect any biases, considering the data sources. Then review the Data Dictionary to get a familiarity with the values and try to understand how to make use of the available data, in purpose of the project scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E9Y5aC0IAA-"
   },
   "source": [
    "<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Analyze**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Analyze stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I-fjg7pNOe4"
   },
   "source": [
    "### **Task 2a. Imports and data loading**\n",
    "\n",
    "Start by importing the packages that you will need to load and explore the dataset. Make sure to use the following import statements:\n",
    "*   `import pandas as pd`\n",
    "\n",
    "*   `import numpy as np`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4Jj3QLINOsL"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJpU5tFvNNDy"
   },
   "source": [
    "Then, load the dataset into a dataframe. Creating a dataframe will help you conduct data manipulation, exploratory data analysis (EDA), and statistical activities.\n",
    "\n",
    "**Note:** As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYk-rdaWNN4G"
   },
   "outputs": [],
   "source": [
    "# Load dataset into dataframe\n",
    "data = pd.read_csv(\"tiktok_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6KgK-M8o3we"
   },
   "source": [
    "### **Task 2b. Understand the data - Inspect the data**\n",
    "\n",
    "View and inspect summary information about the dataframe by **coding the following:**\n",
    "\n",
    "1. `data.head(10)`\n",
    "2. `data.info()`\n",
    "3. `data.describe()`\n",
    "\n",
    "*Consider the following questions:*\n",
    "\n",
    "**Question 1:** When reviewing the first few rows of the dataframe, what do you observe about the data? What does each row represent?\n",
    "\n",
    "**Question 2:** When reviewing the `data.info()` output, what do you notice about the different variables? Are there any null values? Are all of the variables numeric? Does anything else stand out?\n",
    "\n",
    "**Question 3:** When reviewing the `data.describe()` output, what do you notice about the distributions of each variable? Are there any questionable values? Does it seem that there are outlier values?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pW7syBEskCS8",
    "outputId": "e42e3097-a67e-492d-c8d4-08b1625d0b5e"
   },
   "outputs": [],
   "source": [
    "# Display and examine the first ten rows of the dataframe\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uo90wIjK7z-k",
    "outputId": "9924933b-16de-4665-b57e-5c3aa2fd2869"
   },
   "outputs": [],
   "source": [
    "# Get summary info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrdPW1l67zrR",
    "outputId": "5e6c74d7-8980-4914-cbf2-944b99edd5ac"
   },
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrENd-iQZRdA"
   },
   "source": [
    "- Each row represents and observation\n",
    "- There are 11 different variables wit 3 different types: int64, float64 and object. Not all of the are numeric. There is no null values. There is a difference of non-null values between the total video count and the matching observations.\n",
    "- I didn't notice any unusual, questionable values at this phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYx1emvno7U_"
   },
   "source": [
    "### **Task 2c. Understand the data - Investigate the variables**\n",
    "\n",
    "In this phase, you will begin to investigate the variables more closely to better understand them.\n",
    "\n",
    "You know from the project proposal that the ultimate objective is to use machine learning to classify videos as either claims or opinions. A good first step towards understanding the data might therefore be examining the `claim_status` variable. Begin by determining how many videos there are for each different claim status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kb8fPcw3rvvo",
    "outputId": "9e1fc1a2-bd42-4dd6-a569-c2324354a779"
   },
   "outputs": [],
   "source": [
    "# What are the different values for claim status and how many of each are in the data?\n",
    "data.groupby([\"claim_status\"]).count()\n",
    "\n",
    "# or\n",
    "# data[\"claim_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSE317zdZp1q"
   },
   "source": [
    "**Question:** What do you notice about the values shown?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpD-nHv5Cpiy"
   },
   "source": [
    "Next, examine the engagement trends associated with each different claim status.\n",
    "\n",
    "Start by using Boolean masking to filter the data according to claim status, then calculate the mean and median view counts for each claim status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fuwMO66VCri1",
    "outputId": "01c90cf8-2d6d-4b07-c474-4587c3c08010"
   },
   "outputs": [],
   "source": [
    "# What is the average view count of videos with \"claim\" status?\n",
    "claim_status_group = data.groupby([\"claim_status\"])\n",
    "\n",
    "claim_status_group[[\"video_view_count\"]].agg([\"mean\", \"median\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCRPxmpHCrQW",
    "outputId": "c0e053ad-ebfa-44a7-8d11-d349e630ad62"
   },
   "outputs": [],
   "source": [
    "# What is the average view count of videos with \"opinion\" status?\n",
    "mean_claim_status_group = claim_status_group[\"video_view_count\"].mean()\n",
    "\n",
    "mean_claim_status_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zIf6L7cC9be"
   },
   "source": [
    "**Question:** What do you notice about the mean and media within each claim category?\n",
    "\n",
    "- **The mean and median values of each category are similar within each. That makes it a relaible data and not biased with outliers. But there is a huge difference between the view counts of claim to opinion videos.**\n",
    "\n",
    "Now, examine trends associated with the ban status of the author.\n",
    "\n",
    "Use `groupby()` to calculate how many videos there are for each combination of categories of claim status and author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Luu6W5b7DGtt",
    "outputId": "7726d7c8-682e-417b-b753-4b074d1938d1"
   },
   "outputs": [],
   "source": [
    "# Get counts for each group combination of claim status and author ban status\n",
    "ban = data.groupby([\"claim_status\", \"author_ban_status\"]).agg([\"count\"])\n",
    "\n",
    "ban[\"#\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWpGkxCTDHlE"
   },
   "source": [
    "**Question:** What do you notice about the number of claims videos with banned authors? Why might this relationship occur?\n",
    "\n",
    "- **Banned authors are more in claim videos. There might be a correlation between claims and violation of user terms, therefore author_ban_status count is high.**\n",
    "\n",
    "Continue investigating engagement levels, now focusing on `author_ban_status`.\n",
    "\n",
    "Calculate the median video share count of each author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaWqtj3yENy0",
    "outputId": "6323b219-8619-43fb-d66a-699a303e2b8c"
   },
   "outputs": [],
   "source": [
    "video_share_banned = data.groupby([\"author_ban_status\"])\n",
    "\n",
    "video_share_banned[\"video_share_count\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9eIkY8TENkK",
    "outputId": "31972603-ed51-4e63-8261-d644cd2c4bbf"
   },
   "outputs": [],
   "source": [
    "# What's the median video share count of each author ban status?\n",
    "video_share_banned = data.groupby([\"author_ban_status\"])\n",
    "\n",
    "video_share_banned[\"video_share_count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLLZObEHEOQf"
   },
   "source": [
    "**Question:** What do you notice about the share count of banned authors, compared to that of active authors? Explore this in more depth.\n",
    "\n",
    "- **The share of median of banned authors' count is very high compared to the median of active authors count'.**\n",
    "\n",
    "Use `groupby()` to group the data by `author_ban_status`, then use `agg()` to get the count, mean, and median of each of the following columns:\n",
    "* `video_view_count`\n",
    "* `video_like_count`\n",
    "* `video_share_count`\n",
    "\n",
    "Remember, the argument for the `agg()` function is a dictionary whose keys are columns. The values for each column are a list of the calculations you want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVlTvmO-Ebgc",
    "outputId": "9a46a931-7a65-4879-b35b-3541942a8d3c"
   },
   "outputs": [],
   "source": [
    "video_banned = data.groupby(\"author_ban_status\").agg([\"count\", \"mean\", \"median\"])\n",
    "\n",
    "video_banned[[\"video_view_count\", \"video_like_count\", \"video_share_count\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7R3vKUhEb8_"
   },
   "source": [
    "**Question:** What do you notice about the number of views, likes, and shares for banned authors compared to active authors?\n",
    "\n",
    "- **Banned authors' view, like and share counts are much higher than the corresponding counts of active authors' videos**\n",
    "\n",
    "Now, create three new columns to help better understand engagement rates:\n",
    "* `likes_per_view`: represents the number of likes divided by the number of views for each video\n",
    "* `comments_per_view`: represents the number of comments divided by the number of views for each video\n",
    "* `shares_per_view`: represents the number of shares divided by the number of views for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyymCn6oFDP3",
    "outputId": "e4268ae0-a8b8-4410-bb33-2829c5cd4540"
   },
   "outputs": [],
   "source": [
    "# Create a likes_per_view column\n",
    "data[\"likes_per_view\"] = data[\"video_like_count\"]/data[\"video_view_count\"]\n",
    "\n",
    "# Create a comments_per_view column\n",
    "data[\"comments_per_view\"] = data[\"video_comment_count\"]/data[\"video_view_count\"]\n",
    "\n",
    "# Create a shares_per_view column\n",
    "data[\"shares_per_view\"] = data[\"video_share_count\"]/data[\"video_view_count\"]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y238Q5jaFOwQ"
   },
   "source": [
    "Use `groupby()` to compile the information in each of the three newly created columns for each combination of categories of claim status and author ban status, then use `agg()` to calculate the count, the mean, and the median of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZoK3_-bFPW2",
    "outputId": "7fddef17-d3b1-42f8-e656-c0f4c2a4991f"
   },
   "outputs": [],
   "source": [
    "statistics_claim_status = data.groupby([\"claim_status\", \"author_ban_status\"]).agg({\"likes_per_view\": [\"count\", \"mean\", \"median\"], \"comments_per_view\": [\"count\", \"mean\", \"median\"], \"shares_per_view\": [\"count\", \"mean\", \"median\"]})\n",
    "\n",
    "# statistics_claim_status\n",
    "statistics_claim_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLhoV4xDFp_o"
   },
   "source": [
    "**Question:**\n",
    "\n",
    "How does the data for claim videos and opinion videos compare or differ? Consider views, comments, likes, and shares.\n",
    "\n",
    "- **Averages on data for claim videos are higher in each group compared to the opinion videos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tF_82VLgzrQm"
   },
   "source": [
    "<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Construct**\n",
    "\n",
    "**Note**: The Construct stage does not apply to this workflow. The PACE framework can be adapted to fit the specific requirements of any project.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMHV86A6zrQo"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Execute**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document and those below to craft your response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3HxcMZgz6iW"
   },
   "source": [
    "### **Given your efforts, what can you summarize for Rosie Mae Bradshaw and the TikTok data team?**\n",
    "\n",
    "*Note for Learners: Your answer should address TikTok's request for a summary that covers the following points:*\n",
    "\n",
    "*   What percentage of the data is comprised of claims and what percentage is comprised of opinions?\n",
    "*   What factors correlate with a video's claim status?\n",
    "*   What factors correlate with a video's engagement level?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPVfDMum_xYl"
   },
   "source": [
    "- Almost 50% of the videos are claims.\n",
    "- There is a high positive correlation of the banned and under review videos with the claim status videos.\n",
    "- Banned authors' videos have a higher engagement rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHoVQ1xDGZ2C"
   },
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
