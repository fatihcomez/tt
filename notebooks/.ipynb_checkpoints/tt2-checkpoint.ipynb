{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# TT Project\n",
    "Get Started with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJCatj3xzrQZ"
   },
   "source": [
    "You have just started as a data professional at TikTok.\n",
    "\n",
    "The team is still in the early stages of the project. You have received notice that TikTok's leadership team has approved the project proposal. To gain clear insights to prepare for a claims classification model, TikTok's provided data must be examined to begin the process of exploratory data analysis (EDA).\n",
    "\n",
    "A notebook was structured and prepared to help you in this project. Please complete the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# Inspect and analyze data\n",
    "\n",
    "In this activity, you will examine data provided and prepare it for analysis.\n",
    "<br/>\n",
    "\n",
    "**The purpose** of this project is to investigate and understand the data provided. This activity will:\n",
    "\n",
    "1.   Acquaint you with the data\n",
    "\n",
    "2.   Compile summary information about the data\n",
    "\n",
    "3.   Begin the process of EDA and reveal insights contained in the data\n",
    "\n",
    "4.   Prepare you for more in-depth EDA, hypothesis testing, and statistical analysis\n",
    "\n",
    "**The goal** is to construct a dataframe in Python, perform a cursory inspection of the provided dataset, and inform TikTok data team members of your findings.\n",
    "<br/>\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Understand the situation\n",
    "* How can you best prepare to understand and organize the provided TikTok information?\n",
    "\n",
    "**Part 2:** Understand the data\n",
    "\n",
    "* Create a pandas dataframe for data learning and future exploratory data analysis (EDA) and statistical activities\n",
    "\n",
    "* Compile summary information about the data to inform next steps\n",
    "\n",
    "**Part 3:** Understand the variables\n",
    "\n",
    "* Use insights from your examination of the summary data to guide deeper investigation into variables\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjFGokxv2pc5"
   },
   "source": [
    "# **Identify data types and compile summary information**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRUYfzCb4vop"
   },
   "source": [
    "# PACE stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRHb2QQWj99m"
   },
   "source": [
    "## PACE: Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TD5rUDqtNoiH"
   },
   "source": [
    "### **Task 1. Understand the situation**\n",
    "\n",
    "*   How can you best prepare to understand and organize the provided information?\n",
    "\n",
    "\n",
    "*Begin by exploring your dataset and consider reviewing the Data Dictionary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9WkTfMU4_mB"
   },
   "source": [
    "Start with getting familiar with the data files, how they are organized on the disk, folders, etc. Then, try identify collection timespan, if they are 2nd or 3rd sources, how they were collected and if they ara anonymized. I would also try to understand if I should expect any biases, considering the data sources. Then review the Data Dictionary to get a familiarity with the values and try to understand how to make use of the available data, in purpose of the project scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E9Y5aC0IAA-"
   },
   "source": [
    "## PACE: Analyze\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Analyze stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I-fjg7pNOe4"
   },
   "source": [
    "### Task 2a. Imports and data loading\n",
    "Start by importing the packages that you will need to load and explore the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I4Jj3QLINOsL"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJpU5tFvNNDy"
   },
   "source": [
    "Then, load the dataset into a dataframe. Creating a dataframe will help you conduct data manipulation, exploratory data analysis (EDA), and statistical activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oYk-rdaWNN4G"
   },
   "outputs": [],
   "source": [
    "# Load dataset into dataframe\n",
    "data = pd.read_csv(\"../data/tt_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6KgK-M8o3we"
   },
   "source": [
    "### **Task 2b. Understand the data - Inspect the data**\n",
    "\n",
    "View and inspect summary information about the dataframe.\n",
    "\n",
    "*Consider the following questions:*\n",
    "\n",
    "**Question 1:** When reviewing the first few rows of the dataframe, what do you observe about the data? What does each row represent?\n",
    "\n",
    "**Question 2:** When reviewing the `data.info()` output, what do you notice about the different variables? Are there any null values? Are all of the variables numeric? Does anything else stand out?\n",
    "\n",
    "**Question 3:** When reviewing the `data.describe()` output, what do you notice about the distributions of each variable? Are there any questionable values? Does it seem that there are outlier values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pW7syBEskCS8",
    "outputId": "e42e3097-a67e-492d-c8d4-08b1625d0b5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>claim_status</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_duration_sec</th>\n",
       "      <th>video_transcription_text</th>\n",
       "      <th>verified_status</th>\n",
       "      <th>author_ban_status</th>\n",
       "      <th>video_view_count</th>\n",
       "      <th>video_like_count</th>\n",
       "      <th>video_share_count</th>\n",
       "      <th>video_download_count</th>\n",
       "      <th>video_comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>claim</td>\n",
       "      <td>7017666017</td>\n",
       "      <td>59</td>\n",
       "      <td>someone shared with me that drone deliveries a...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>under review</td>\n",
       "      <td>343296.0</td>\n",
       "      <td>19425.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>claim</td>\n",
       "      <td>4014381136</td>\n",
       "      <td>32</td>\n",
       "      <td>someone shared with me that there are more mic...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>140877.0</td>\n",
       "      <td>77355.0</td>\n",
       "      <td>19034.0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>claim</td>\n",
       "      <td>9859838091</td>\n",
       "      <td>31</td>\n",
       "      <td>someone shared with me that american industria...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>902185.0</td>\n",
       "      <td>97690.0</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>claim</td>\n",
       "      <td>1866847991</td>\n",
       "      <td>25</td>\n",
       "      <td>someone shared with me that the metro of st. p...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>437506.0</td>\n",
       "      <td>239954.0</td>\n",
       "      <td>34812.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>claim</td>\n",
       "      <td>7105231098</td>\n",
       "      <td>19</td>\n",
       "      <td>someone shared with me that the number of busi...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>56167.0</td>\n",
       "      <td>34987.0</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>claim</td>\n",
       "      <td>8972200955</td>\n",
       "      <td>35</td>\n",
       "      <td>someone shared with me that gross domestic pro...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>under review</td>\n",
       "      <td>336647.0</td>\n",
       "      <td>175546.0</td>\n",
       "      <td>62303.0</td>\n",
       "      <td>4293.0</td>\n",
       "      <td>1857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>claim</td>\n",
       "      <td>4958886992</td>\n",
       "      <td>16</td>\n",
       "      <td>someone shared with me that elvis presley has ...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>750345.0</td>\n",
       "      <td>486192.0</td>\n",
       "      <td>193911.0</td>\n",
       "      <td>8616.0</td>\n",
       "      <td>5446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>claim</td>\n",
       "      <td>2270982263</td>\n",
       "      <td>41</td>\n",
       "      <td>someone shared with me that the best selling s...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>547532.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>claim</td>\n",
       "      <td>5235769692</td>\n",
       "      <td>50</td>\n",
       "      <td>someone shared with me that about half of the ...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>24819.0</td>\n",
       "      <td>10160.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>claim</td>\n",
       "      <td>4660861094</td>\n",
       "      <td>45</td>\n",
       "      <td>someone shared with me that it would take a 50...</td>\n",
       "      <td>verified</td>\n",
       "      <td>active</td>\n",
       "      <td>931587.0</td>\n",
       "      <td>171051.0</td>\n",
       "      <td>67739.0</td>\n",
       "      <td>4104.0</td>\n",
       "      <td>2540.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # claim_status    video_id  video_duration_sec  \\\n",
       "0   1        claim  7017666017                  59   \n",
       "1   2        claim  4014381136                  32   \n",
       "2   3        claim  9859838091                  31   \n",
       "3   4        claim  1866847991                  25   \n",
       "4   5        claim  7105231098                  19   \n",
       "5   6        claim  8972200955                  35   \n",
       "6   7        claim  4958886992                  16   \n",
       "7   8        claim  2270982263                  41   \n",
       "8   9        claim  5235769692                  50   \n",
       "9  10        claim  4660861094                  45   \n",
       "\n",
       "                            video_transcription_text verified_status  \\\n",
       "0  someone shared with me that drone deliveries a...    not verified   \n",
       "1  someone shared with me that there are more mic...    not verified   \n",
       "2  someone shared with me that american industria...    not verified   \n",
       "3  someone shared with me that the metro of st. p...    not verified   \n",
       "4  someone shared with me that the number of busi...    not verified   \n",
       "5  someone shared with me that gross domestic pro...    not verified   \n",
       "6  someone shared with me that elvis presley has ...    not verified   \n",
       "7  someone shared with me that the best selling s...    not verified   \n",
       "8  someone shared with me that about half of the ...    not verified   \n",
       "9  someone shared with me that it would take a 50...        verified   \n",
       "\n",
       "  author_ban_status  video_view_count  video_like_count  video_share_count  \\\n",
       "0      under review          343296.0           19425.0              241.0   \n",
       "1            active          140877.0           77355.0            19034.0   \n",
       "2            active          902185.0           97690.0             2858.0   \n",
       "3            active          437506.0          239954.0            34812.0   \n",
       "4            active           56167.0           34987.0             4110.0   \n",
       "5      under review          336647.0          175546.0            62303.0   \n",
       "6            active          750345.0          486192.0           193911.0   \n",
       "7            active          547532.0            1072.0               50.0   \n",
       "8            active           24819.0           10160.0             1050.0   \n",
       "9            active          931587.0          171051.0            67739.0   \n",
       "\n",
       "   video_download_count  video_comment_count  \n",
       "0                   1.0                  0.0  \n",
       "1                1161.0                684.0  \n",
       "2                 833.0                329.0  \n",
       "3                1234.0                584.0  \n",
       "4                 547.0                152.0  \n",
       "5                4293.0               1857.0  \n",
       "6                8616.0               5446.0  \n",
       "7                  22.0                 11.0  \n",
       "8                  53.0                 27.0  \n",
       "9                4104.0               2540.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display and examine the first ten rows of the dataframe\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uo90wIjK7z-k",
    "outputId": "9924933b-16de-4665-b57e-5c3aa2fd2869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19382 entries, 0 to 19381\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   #                         19382 non-null  int64  \n",
      " 1   claim_status              19084 non-null  object \n",
      " 2   video_id                  19382 non-null  int64  \n",
      " 3   video_duration_sec        19382 non-null  int64  \n",
      " 4   video_transcription_text  19084 non-null  object \n",
      " 5   verified_status           19382 non-null  object \n",
      " 6   author_ban_status         19382 non-null  object \n",
      " 7   video_view_count          19084 non-null  float64\n",
      " 8   video_like_count          19084 non-null  float64\n",
      " 9   video_share_count         19084 non-null  float64\n",
      " 10  video_download_count      19084 non-null  float64\n",
      " 11  video_comment_count       19084 non-null  float64\n",
      "dtypes: float64(5), int64(3), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get summary info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rrdPW1l67zrR",
    "outputId": "5e6c74d7-8980-4914-cbf2-944b99edd5ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_duration_sec</th>\n",
       "      <th>video_view_count</th>\n",
       "      <th>video_like_count</th>\n",
       "      <th>video_share_count</th>\n",
       "      <th>video_download_count</th>\n",
       "      <th>video_comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19382.000000</td>\n",
       "      <td>1.938200e+04</td>\n",
       "      <td>19382.000000</td>\n",
       "      <td>19084.000000</td>\n",
       "      <td>19084.000000</td>\n",
       "      <td>19084.000000</td>\n",
       "      <td>19084.000000</td>\n",
       "      <td>19084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9691.500000</td>\n",
       "      <td>5.627454e+09</td>\n",
       "      <td>32.421732</td>\n",
       "      <td>254708.558688</td>\n",
       "      <td>84304.636030</td>\n",
       "      <td>16735.248323</td>\n",
       "      <td>1049.429627</td>\n",
       "      <td>349.312146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5595.245794</td>\n",
       "      <td>2.536440e+09</td>\n",
       "      <td>16.229967</td>\n",
       "      <td>322893.280814</td>\n",
       "      <td>133420.546814</td>\n",
       "      <td>32036.174350</td>\n",
       "      <td>2004.299894</td>\n",
       "      <td>799.638865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.234959e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4846.250000</td>\n",
       "      <td>3.430417e+09</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4942.500000</td>\n",
       "      <td>810.750000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9691.500000</td>\n",
       "      <td>5.618664e+09</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>9954.500000</td>\n",
       "      <td>3403.500000</td>\n",
       "      <td>717.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14536.750000</td>\n",
       "      <td>7.843960e+09</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>504327.000000</td>\n",
       "      <td>125020.000000</td>\n",
       "      <td>18222.000000</td>\n",
       "      <td>1156.250000</td>\n",
       "      <td>292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19382.000000</td>\n",
       "      <td>9.999873e+09</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>999817.000000</td>\n",
       "      <td>657830.000000</td>\n",
       "      <td>256130.000000</td>\n",
       "      <td>14994.000000</td>\n",
       "      <td>9599.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  #      video_id  video_duration_sec  video_view_count  \\\n",
       "count  19382.000000  1.938200e+04        19382.000000      19084.000000   \n",
       "mean    9691.500000  5.627454e+09           32.421732     254708.558688   \n",
       "std     5595.245794  2.536440e+09           16.229967     322893.280814   \n",
       "min        1.000000  1.234959e+09            5.000000         20.000000   \n",
       "25%     4846.250000  3.430417e+09           18.000000       4942.500000   \n",
       "50%     9691.500000  5.618664e+09           32.000000       9954.500000   \n",
       "75%    14536.750000  7.843960e+09           47.000000     504327.000000   \n",
       "max    19382.000000  9.999873e+09           60.000000     999817.000000   \n",
       "\n",
       "       video_like_count  video_share_count  video_download_count  \\\n",
       "count      19084.000000       19084.000000          19084.000000   \n",
       "mean       84304.636030       16735.248323           1049.429627   \n",
       "std       133420.546814       32036.174350           2004.299894   \n",
       "min            0.000000           0.000000              0.000000   \n",
       "25%          810.750000         115.000000              7.000000   \n",
       "50%         3403.500000         717.000000             46.000000   \n",
       "75%       125020.000000       18222.000000           1156.250000   \n",
       "max       657830.000000      256130.000000          14994.000000   \n",
       "\n",
       "       video_comment_count  \n",
       "count         19084.000000  \n",
       "mean            349.312146  \n",
       "std             799.638865  \n",
       "min               0.000000  \n",
       "25%               1.000000  \n",
       "50%               9.000000  \n",
       "75%             292.000000  \n",
       "max            9599.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrENd-iQZRdA"
   },
   "source": [
    "- Each row represents and observation\n",
    "- There are 11 different variables wit 3 different types: int64, float64 and object. Not all of the are numeric. There is no null values. There is a difference of non-null values between the total video count and the matching observations.\n",
    "- I didn't notice any unusual, questionable values at this phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYx1emvno7U_"
   },
   "source": [
    "### **Task 2c. Understand the data - Investigate the variables**\n",
    "\n",
    "In this phase, you will begin to investigate the variables more closely to better understand them.\n",
    "\n",
    "You know from the project proposal that the ultimate objective is to use machine learning to classify videos as either claims or opinions. A good first step towards understanding the data might therefore be examining the `claim_status` variable. Begin by determining how many videos there are for each different claim status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Kb8fPcw3rvvo",
    "outputId": "9e1fc1a2-bd42-4dd6-a569-c2324354a779"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_duration_sec</th>\n",
       "      <th>video_transcription_text</th>\n",
       "      <th>verified_status</th>\n",
       "      <th>author_ban_status</th>\n",
       "      <th>video_view_count</th>\n",
       "      <th>video_like_count</th>\n",
       "      <th>video_share_count</th>\n",
       "      <th>video_download_count</th>\n",
       "      <th>video_comment_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "      <td>9608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "      <td>9476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 #  video_id  video_duration_sec  video_transcription_text  \\\n",
       "claim_status                                                                 \n",
       "claim         9608      9608                9608                      9608   \n",
       "opinion       9476      9476                9476                      9476   \n",
       "\n",
       "              verified_status  author_ban_status  video_view_count  \\\n",
       "claim_status                                                         \n",
       "claim                    9608               9608              9608   \n",
       "opinion                  9476               9476              9476   \n",
       "\n",
       "              video_like_count  video_share_count  video_download_count  \\\n",
       "claim_status                                                              \n",
       "claim                     9608               9608                  9608   \n",
       "opinion                   9476               9476                  9476   \n",
       "\n",
       "              video_comment_count  \n",
       "claim_status                       \n",
       "claim                        9608  \n",
       "opinion                      9476  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the different values for claim status and how many of each are in the data?\n",
    "data.groupby([\"claim_status\"]).count()\n",
    "\n",
    "# or\n",
    "# data[\"claim_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSE317zdZp1q"
   },
   "source": [
    "**Question:** What do you notice about the values shown?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpD-nHv5Cpiy"
   },
   "source": [
    "Next, examine the engagement trends associated with each different claim status.\n",
    "\n",
    "Start by using Boolean masking to filter the data according to claim status, then calculate the mean and median view counts for each claim status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fuwMO66VCri1",
    "outputId": "01c90cf8-2d6d-4b07-c474-4587c3c08010"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">video_view_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>501029.452748</td>\n",
       "      <td>501555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>4956.432250</td>\n",
       "      <td>4953.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_view_count          \n",
       "                         mean    median\n",
       "claim_status                           \n",
       "claim           501029.452748  501555.0\n",
       "opinion           4956.432250    4953.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the average view count of videos with \"claim\" status?\n",
    "claim_status_group = data.groupby([\"claim_status\"])\n",
    "\n",
    "claim_status_group[[\"video_view_count\"]].agg([\"mean\", \"median\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FCRPxmpHCrQW",
    "outputId": "c0e053ad-ebfa-44a7-8d11-d349e630ad62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "claim_status\n",
       "claim      501029.452748\n",
       "opinion      4956.432250\n",
       "Name: video_view_count, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the average view count of videos with \"opinion\" status?\n",
    "mean_claim_status_group = claim_status_group[\"video_view_count\"].mean()\n",
    "\n",
    "mean_claim_status_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zIf6L7cC9be"
   },
   "source": [
    "**Question:** What do you notice about the mean and media within each claim category?\n",
    "\n",
    "- **The mean and median values of each category are similar within each. That makes it a relaible data and not biased with outliers. But there is a huge difference between the view counts of claim to opinion videos.**\n",
    "\n",
    "Now, examine trends associated with the ban status of the author.\n",
    "\n",
    "Use `groupby()` to calculate how many videos there are for each combination of categories of claim status and author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Luu6W5b7DGtt",
    "outputId": "7726d7c8-682e-417b-b753-4b074d1938d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim_status</th>\n",
       "      <th>author_ban_status</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">claim</th>\n",
       "      <th>active</th>\n",
       "      <td>6566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banned</th>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under review</th>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">opinion</th>\n",
       "      <th>active</th>\n",
       "      <td>8817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banned</th>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under review</th>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count\n",
       "claim_status author_ban_status       \n",
       "claim        active              6566\n",
       "             banned              1439\n",
       "             under review        1603\n",
       "opinion      active              8817\n",
       "             banned               196\n",
       "             under review         463"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get counts for each group combination of claim status and author ban status\n",
    "ban = data.groupby([\"claim_status\", \"author_ban_status\"]).agg([\"count\"])\n",
    "\n",
    "ban[\"#\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWpGkxCTDHlE"
   },
   "source": [
    "**Question:** What do you notice about the number of claims videos with banned authors? Why might this relationship occur?\n",
    "\n",
    "- **Banned authors are more in claim videos. There might be a correlation between claims and violation of user terms, therefore author_ban_status count is high.**\n",
    "\n",
    "Continue investigating engagement levels, now focusing on `author_ban_status`.\n",
    "\n",
    "Calculate the median video share count of each author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jaWqtj3yENy0",
    "outputId": "6323b219-8619-43fb-d66a-699a303e2b8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_ban_status\n",
       "active            437.0\n",
       "banned          14468.0\n",
       "under review     9444.0\n",
       "Name: video_share_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_share_banned = data.groupby([\"author_ban_status\"])\n",
    "\n",
    "video_share_banned[\"video_share_count\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "V9eIkY8TENkK",
    "outputId": "31972603-ed51-4e63-8261-d644cd2c4bbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_ban_status\n",
       "active            437.0\n",
       "banned          14468.0\n",
       "under review     9444.0\n",
       "Name: video_share_count, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the median video share count of each author ban status?\n",
    "video_share_banned = data.groupby([\"author_ban_status\"])\n",
    "\n",
    "video_share_banned[\"video_share_count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLLZObEHEOQf"
   },
   "source": [
    "**Question:** What do you notice about the share count of banned authors, compared to that of active authors? Explore this in more depth.\n",
    "\n",
    "- **The share of median of banned authors' count is very high compared to the median of active authors count'.**\n",
    "\n",
    "Use `groupby()` to group the data by `author_ban_status`, then use `agg()` to get the count, mean, and median of each of the following columns:\n",
    "* `video_view_count`\n",
    "* `video_like_count`\n",
    "* `video_share_count`\n",
    "\n",
    "Remember, the argument for the `agg()` function is a dictionary whose keys are columns. The values for each column are a list of the calculations you want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fVlTvmO-Ebgc",
    "outputId": "9a46a931-7a65-4879-b35b-3541942a8d3c"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1941\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1942\u001b[39m     res_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    862\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m     res = extract_result(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[39m, in \u001b[36mGroupBy.mean.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   2451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2452\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._cython_agg_general(\n\u001b[32m   2453\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2454\u001b[39m         alt=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2455\u001b[39m         numeric_only=numeric_only,\n\u001b[32m   2456\u001b[39m     )\n\u001b[32m   2457\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\series.py:6549\u001b[39m, in \u001b[36mSeries.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m   6541\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m   6543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6547\u001b[39m     **kwargs,\n\u001b[32m   6548\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6549\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[39m, in \u001b[36mNDFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12413\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  12414\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12415\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12418\u001b[39m     **kwargs,\n\u001b[32m  12419\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12421\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12422\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12375\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12379\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6453\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6454\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6455\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6456\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6457\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[39m, in \u001b[36mnanmean\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    718\u001b[39m count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m the_sum = \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m the_sum = _ensure_numeric(the_sum)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\numpy\\_core\\_methods.py:52\u001b[39m, in \u001b[36m_sum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     51\u001b[39m          initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"int\") to str",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Use `groupby()` to group the data by `author_ban_status`, then use `agg()` to get the count, mean, and median of each of the following columns: `video_view_count`, `video_like_count`, `video_share_count`\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m video_banned = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauthor_ban_status\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedian\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m video_banned[[\u001b[33m\"\u001b[39m\u001b[33mvideo_view_count\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvideo_like_count\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvideo_share_count\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1431\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1434\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\apply.py:193\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_dict_like()\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[32m    196\u001b[39m     f = com.get_cython_func(func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\apply.py:326\u001b[39m, in \u001b[36mApply.agg_list_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_list_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    319\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m    Compute aggregation in the case of a list-like argument.\u001b[39;00m\n\u001b[32m    321\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    324\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\apply.py:1571\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_list_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1566\u001b[39m \u001b[38;5;66;03m# Only set as_index=True on groupby objects, not Window or Resample\u001b[39;00m\n\u001b[32m   1567\u001b[39m \u001b[38;5;66;03m# that inherit from this class.\u001b[39;00m\n\u001b[32m   1568\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1569\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1570\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     keys, results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1572\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_list_like(keys, results)\n\u001b[32m   1573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\apply.py:385\u001b[39m, in \u001b[36mApply.compute_list_like\u001b[39m\u001b[34m(self, op_name, selected_obj, kwargs)\u001b[39m\n\u001b[32m    379\u001b[39m colg = obj._gotitem(col, ndim=\u001b[32m1\u001b[39m, subset=selected_obj.iloc[:, index])\n\u001b[32m    380\u001b[39m args = (\n\u001b[32m    381\u001b[39m     [\u001b[38;5;28mself\u001b[39m.axis, *\u001b[38;5;28mself\u001b[39m.args]\n\u001b[32m    382\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args\n\u001b[32m    384\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m new_res = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m results.append(new_res)\n\u001b[32m    387\u001b[39m indices.append(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:257\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    255\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = engine\n\u001b[32m    256\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:362\u001b[39m, in \u001b[36mSeriesGroupBy._aggregate_multiple_funcs\u001b[39m\u001b[34m(self, arg, *args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[32m    361\u001b[39m         key = base.OutputKey(label=name, position=idx)\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         results[key] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results.values()):\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:249\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m engine_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    248\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc.Iterable):\n\u001b[32m    252\u001b[39m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[32m    253\u001b[39m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[32m    254\u001b[39m     func = maybe_mangle_lambdas(func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[39m, in \u001b[36mGroupBy.mean\u001b[39m\u001b[34m(self, numeric_only, engine, engine_kwargs)\u001b[39m\n\u001b[32m   2445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._numba_agg_general(\n\u001b[32m   2446\u001b[39m         grouped_mean,\n\u001b[32m   2447\u001b[39m         executor.float_dtype_mapping,\n\u001b[32m   2448\u001b[39m         engine_kwargs,\n\u001b[32m   2449\u001b[39m         min_periods=\u001b[32m0\u001b[39m,\n\u001b[32m   2450\u001b[39m     )\n\u001b[32m   2451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2452\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2453\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2454\u001b[39m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2456\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[39m, in \u001b[36mGroupBy._cython_agg_general\u001b[39m\u001b[34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m   1995\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n\u001b[32m   1996\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m1998\u001b[39m new_mgr = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1999\u001b[39m res = \u001b[38;5;28mself\u001b[39m._wrap_agged_manager(new_mgr)\n\u001b[32m   2000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33midxmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33midxmax\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\internals\\base.py:367\u001b[39m, in \u001b[36mSingleDataManager.grouped_reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[32m    366\u001b[39m     arr = \u001b[38;5;28mself\u001b[39m.array\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m     index = default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[32m    370\u001b[39m     mgr = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_array(res, index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[39m, in \u001b[36mGroupBy._cython_agg_general.<locals>.array_func\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1992\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m   1994\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1995\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\ml\\tt\\env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1944\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1945\u001b[39m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1946\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1948\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ser.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m   1949\u001b[39m     res_values = res_values.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Use `groupby()` to group the data by `author_ban_status`, then use `agg()` to get the count, mean, and median of each of the following columns: `video_view_count`, `video_like_count`, `video_share_count`\n",
    "\n",
    "video_banned = data.groupby(\"author_ban_status\").agg([\"count\", \"mean\", \"median\"])\n",
    "\n",
    "video_banned[[\"video_view_count\", \"video_like_count\", \"video_share_count\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7R3vKUhEb8_"
   },
   "source": [
    "**Question:** What do you notice about the number of views, likes, and shares for banned authors compared to active authors?\n",
    "\n",
    "- **Banned authors' view, like and share counts are much higher than the corresponding counts of active authors' videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyymCn6oFDP3",
    "outputId": "e4268ae0-a8b8-4410-bb33-2829c5cd4540"
   },
   "outputs": [],
   "source": [
    "# Create three new columns to help better understand engagement rates\n",
    "\n",
    "# Create a `likes_per_view column` which represents the number of likes divided by the number of views for each video\n",
    "data[\"likes_per_view\"] = data[\"video_like_count\"]/data[\"video_view_count\"]\n",
    "\n",
    "# Create a `comments_per_view column` which represents the number of comments divided by the number of views for each video\n",
    "data[\"comments_per_view\"] = data[\"video_comment_count\"]/data[\"video_view_count\"]\n",
    "\n",
    "# Create a `shares_per_view column` which represents the number of shares divided by the number of views for each video\n",
    "data[\"shares_per_view\"] = data[\"video_share_count\"]/data[\"video_view_count\"]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZoK3_-bFPW2",
    "outputId": "7fddef17-d3b1-42f8-e656-c0f4c2a4991f"
   },
   "outputs": [],
   "source": [
    "# Use `groupby()` to compile the information in each of the three newly created columns for each combination of categories of claim status and author ban status, then use `agg()` to calculate the count, the mean, and the median of each group\n",
    "\n",
    "statistics_claim_status = data.groupby([\"claim_status\", \"author_ban_status\"]).agg({\"likes_per_view\": [\"count\", \"mean\", \"median\"], \"comments_per_view\": [\"count\", \"mean\", \"median\"], \"shares_per_view\": [\"count\", \"mean\", \"median\"]})\n",
    "\n",
    "# statistics_claim_status\n",
    "statistics_claim_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLhoV4xDFp_o"
   },
   "source": [
    "**Question:**\n",
    "\n",
    "How does the data for claim videos and opinion videos compare or differ? Consider views, comments, likes, and shares.\n",
    "\n",
    "- **Averages on data for claim videos are higher in each group compared to the opinion videos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tF_82VLgzrQm"
   },
   "source": [
    "## PACE: Construct\n",
    "\n",
    "**Note**: The Construct stage does not apply to this workflow. The PACE framework can be adapted to fit the specific requirements of any project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMHV86A6zrQo"
   },
   "source": [
    "## PACE: Execute\n",
    "\n",
    "Consider the questions in your PACE Strategy Document and those below to craft your response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3HxcMZgz6iW"
   },
   "source": [
    "### **Given your efforts, what can you summarize for Rosie Mae Bradshaw and the TikTok data team?**\n",
    "\n",
    "*Note for Learners: Your answer should address TikTok's request for a summary that covers the following points:*\n",
    "\n",
    "*   What percentage of the data is comprised of claims and what percentage is comprised of opinions?\n",
    "*   What factors correlate with a video's claim status?\n",
    "*   What factors correlate with a video's engagement level?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPVfDMum_xYl"
   },
   "source": [
    "- Almost 50% of the videos are claims.\n",
    "- There is a high positive correlation of the banned and under review videos with the claim status videos.\n",
    "- Banned authors' videos have a higher engagement rate."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
