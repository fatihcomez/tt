{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **TT Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJCatj3xzrQZ"
   },
   "source": [
    "# Introduction\n",
    "TT team works on a project to introduce a claims classification ML model to decrease the manual control need. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents \n",
    "The whole project flow will be acc. to the PACE framework stages (Plan, Analyze, Construct and Execute) and 5 activities *(Inspect and analyze data (pre-EDA), EDA, Hypothesis testing, Regression modeling and ML)* will be covered in 3 main parts. \n",
    "\n",
    "These 3 main parts are: \n",
    "1. Common part, which includes Plan & Analyze stages of PACE for:\n",
    "   - Inspect and analyze data (Pre-EDA)\n",
    "   - EDA\n",
    "   - Hypothesis testing\n",
    "   - Regression modeling \n",
    "   - ML\n",
    "\n",
    "2. Basic part, which includes Construct & Execute stages of PACE for:\n",
    "   - Inspect and analyze data (pre-EDA)\n",
    "   - EDA\n",
    "   - Hypothesis testing     \n",
    "\n",
    "3. Advanced part, which includes Construct & Execute stages of PACE seperately for:\n",
    "   - Regression modeling\n",
    "   - ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Common part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pace: Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Go Beyond the Numbers: Translate Data into Insights**<br>\n",
    "First, TT's provided data must be examined to gain insights to begin the EDA process in the next steps. In other words, twe will try to understand the situation. \n",
    "\n",
    "The management team requires: \n",
    "\n",
    "- a graph comparing claim to opinion counts,\n",
    "- boxplots to check important variables for outliers, \n",
    "- a breakdown of “author ban status” counts, <br>\n",
    "\n",
    "and a Tableau dashboard would be really useful in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to start reviewing the data dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains: \n",
    "\n",
    "**19,383 rows** – Each row represents a different published TikTok video in which a claim/opinion has been made.\n",
    "\n",
    "**12 columns** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column name              | Type  | Description                                                                                                                                              |\n",
    "|--------------------------|-------|----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| #                        | int   | TikTok assigned number for video with claim/opinion.                                                                                                     |\n",
    "| claim_status             | obj   | Whether the published video has been identified as an “opinion” or a “claim.” In this dataset, an “opinion” refers to an individual’s or group’s personal belief or thought. A “claim” refers to information that is either unsourced or from an unverified source. |\n",
    "| video_id                 | int   | Random identifying number assigned to video upon publication on TikTok.                                                                                  |\n",
    "| video_duration_sec       | int   | How long the published video is measured in seconds.                                                                                                     |\n",
    "| video_transcription_text | obj   | Transcribed text of the words spoken in the published video.                                                                                             |\n",
    "| verified_status          | obj   | Indicates the status of the TikTok user who published the video in terms of their verification, either “verified” or “not verified.”                    |\n",
    "| author_ban_status        | obj   | Indicates the status of the TikTok user who published the video in terms of their permissions: “active,” “under scrutiny,” or “banned.”                |\n",
    "| video_view_count         | float | The total number of times the published video has been viewed.                                                                                           |\n",
    "| video_like_count         | float | The total number of times the published video has been liked by other users.                                                                            |\n",
    "| video_share_count        | float | The total number of times the published video has been shared by other users.                                                                           |\n",
    "| video_download_count     | float | The total number of times the published video has been downloaded by other users.                                                                       |\n",
    "| video_comment_count      | float | The total number of comments on the published video.                                                                                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9WkTfMU4_mB"
   },
   "source": [
    "The project will be hosted on GitHub along with a folder structure recently adapted to also host the dataset. \n",
    "\n",
    "Dataset is a single CSV file of ~3 MB. \n",
    "\n",
    "It is a synthetic data and not required to check resources or details like the collection time span and further similar details in purpose of the project scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "**Inspect and analyze data**\n",
    "\n",
    "*The purpose*: Investigate and understand the data provided. \n",
    "\n",
    "1.   Acquaint with the data\n",
    "2.   Compile summary information about the data\n",
    "3.   Begin the process of EDA and reveal insights contained in the data\n",
    "4.   Prepare for more in-depth EDA, hypothesis testing, and statistical analysis\n",
    "\n",
    "*The goal*: \n",
    "- construct a dataframe in Python,\n",
    "- perform a cursory inspection of the provided dataset,\n",
    "- inform data team members of the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- EDA and boxplots especially are best to identify outliers.\n",
    "\n",
    "- The descriptive statistics shall be useful to review how the outliers impact or skew the data. Then, we may decide either to keep them or blend them within the data frame or even get rid of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Power of Statistics**\n",
    "\n",
    "*The purpose*: Demostrate knowledge of how to prepare, create, and analyze hypothesis tests.\n",
    "\n",
    "*The goal* : Apply descriptive and inferential statistics, probability distributions, and hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1. Identify any outliers (in context of EDA)**\n",
    "Using EDA and boxplots we can identify outliers and use also descriptive statistics to review how the outliers impact or skew the data. Then, we may decide either to keep them or blend them within the data frame or even get rid of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1. Data exploration and hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your research question for this data project? Later on, you will need to formulate the null and alternative hypotheses as the first step of your hypothesis test. Consider your research question now, at the start of this task.\n",
    "\n",
    "Whether there is a statistical difference in the data between verified and unverified accounts. \n",
    "\n",
    "We will conduct a two-sample hypothesis test of verified versus unverified accounts in terms of video view counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E9Y5aC0IAA-"
   },
   "source": [
    "## pAce: Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I-fjg7pNOe4"
   },
   "source": [
    "### Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4Jj3QLINOsL"
   },
   "outputs": [],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import packages for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import packages for statistical analysis/hypothesis testing\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJpU5tFvNNDy"
   },
   "source": [
    "Creating a dataframe will help to conduct data manipulation, EDA and statistical activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYk-rdaWNN4G"
   },
   "outputs": [],
   "source": [
    "# Load dataset into dataframe\n",
    "data = pd.read_csv(\"../data/tt_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and examine the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the data\n",
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get basic information about the data, using `.info()`\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 11 different variables with 3 different types: int64, float64 and object.\n",
    "- Not all of them are numeric.\n",
    "- Ther are no null values.\n",
    "- There is a difference of non-null values between the total video count and the matching observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a table of descriptive statistics, using `.describe()`\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6KgK-M8o3we"
   },
   "source": [
    "### **Task 2b. Understand the data - Inspect the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pW7syBEskCS8",
    "outputId": "e42e3097-a67e-492d-c8d4-08b1625d0b5e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display and examine the first ten rows of the dataframe\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** When reviewing the first few rows of the dataframe, what do you observe about the data? What does each row represent?\n",
    "Each row represents and observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uo90wIjK7z-k",
    "outputId": "9924933b-16de-4665-b57e-5c3aa2fd2869",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get summary info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 different variables wit 3 different types: int64, float64 and object. Not all are numeric. There is no null values. There is a difference of non-null values between the total video count and the matching observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrdPW1l67zrR",
    "outputId": "5e6c74d7-8980-4914-cbf2-944b99edd5ac",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** When reviewing the `data.describe()` output, what do you notice about the distributions of each variable? Are there any questionable values? Does it seem that there are outlier values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2. Data exploration** (tt4)\n",
    "\n",
    "Use descriptive statistics to conduct Exploratory Data Analysis (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop missing values if OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "data = data.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows after handling missing values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the relationship between `verified_status` and `video_view_count`. One approach is to examine the mean value of `video_view_count` for each group of `verified_status` in the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean `video_view_count` for each group in `verified_status`\n",
    "\n",
    "# Calculate mean for `verified_status` = \"verified\"\n",
    "verified = data[data[\"verified_status\"] == \"verified\"]\n",
    "verified[\"video_view_count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean for `verified_status` = \"not verified\"\n",
    "not_verified = data[data[\"verified_status\"] == \"not verified\"]\n",
    "not_verified[\"video_view_count\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYx1emvno7U_"
   },
   "source": [
    "### **Task 2c. Understand the data - Investigate the variables**\n",
    "Begin to investigate the variables more closely to better understand them.\n",
    "\n",
    "As the ultimate objective is to use machine learning to classify videos as either claims or opinions, a good first step towards understanding the data might be examining the `claim_status` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kb8fPcw3rvvo",
    "outputId": "9e1fc1a2-bd42-4dd6-a569-c2324354a779"
   },
   "outputs": [],
   "source": [
    "# What are the different values for claim status and how many of each are in the data?\n",
    "data.groupby([\"claim_status\"]).count()\n",
    "\n",
    "# or\n",
    "# data[\"claim_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSE317zdZp1q"
   },
   "source": [
    "Values are in more or less in balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpD-nHv5Cpiy"
   },
   "source": [
    "Next, examine the engagement trends associated with each different claim status.\n",
    "\n",
    "Start by using Boolean masking to filter the data according to claim status, then calculate the mean and median view counts for each claim status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fuwMO66VCri1",
    "outputId": "01c90cf8-2d6d-4b07-c474-4587c3c08010"
   },
   "outputs": [],
   "source": [
    "# Average view count of videos with \"claim\" status\n",
    "claim_status_group = data.groupby([\"claim_status\"])\n",
    "\n",
    "claim_status_group[[\"video_view_count\"]].agg([\"mean\", \"median\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCRPxmpHCrQW",
    "outputId": "c0e053ad-ebfa-44a7-8d11-d349e630ad62"
   },
   "outputs": [],
   "source": [
    "# Average view count of videos with \"opinion\" status\n",
    "mean_claim_status_group = claim_status_group[\"video_view_count\"].mean()\n",
    "\n",
    "mean_claim_status_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zIf6L7cC9be"
   },
   "source": [
    "The mean and median values of each category are similar within each. That makes it a relaible data and not biased with outliers. But there is a huge difference between the view counts of claim to opinion videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, examine trends associated with the ban status of the author.\n",
    "\n",
    "Use `groupby()` to calculate how many videos there are for each combination of categories of claim status and author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Luu6W5b7DGtt",
    "outputId": "7726d7c8-682e-417b-b753-4b074d1938d1"
   },
   "outputs": [],
   "source": [
    "# Get counts for each group combination of claim status and author ban status, using `groupby()`\n",
    "ban = data.groupby([\"claim_status\", \"author_ban_status\"]).agg([\"count\"])\n",
    "\n",
    "ban[\"#\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWpGkxCTDHlE"
   },
   "source": [
    "Banned authors are more in claim videos. There might be a correlation between claims and violation of user terms, therefore `author_ban_status count` is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue investigating engagement levels, now focusing on `author_ban_status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaWqtj3yENy0",
    "outputId": "6323b219-8619-43fb-d66a-699a303e2b8c"
   },
   "outputs": [],
   "source": [
    "# Calculate the median video share count of each `author_ban_status`\n",
    "video_share_banned = data.groupby([\"author_ban_status\"])\n",
    "\n",
    "video_share_banned[\"video_share_count\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9eIkY8TENkK",
    "outputId": "31972603-ed51-4e63-8261-d644cd2c4bbf"
   },
   "outputs": [],
   "source": [
    "# Calculate the median `video_share_count` of each `author_ban_status`\n",
    "video_share_banned = data.groupby([\"author_ban_status\"])\n",
    "\n",
    "video_share_banned[\"video_share_count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLLZObEHEOQf"
   },
   "source": [
    "The share of median of banned authors' count is very high compared to the median of active authors count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVlTvmO-Ebgc",
    "outputId": "9a46a931-7a65-4879-b35b-3541942a8d3c"
   },
   "outputs": [],
   "source": [
    "# Use `groupby()` to group the data by `author_ban_status`, then use `agg()` to get the count, mean, and median of each of the following columns: `video_view_count`, `video_like_count`, `video_share_count`\n",
    "# (The argument for the `agg()` function is a dictionary whose keys are columns. The values for each column are a list of the calculations you want to perform)\n",
    "\n",
    "# video_banned = data.groupby(\"author_ban_status\").agg([\"count\", \"mean\", \"median\"])\n",
    "\n",
    "# video_banned[[\"video_view_count\", \"video_like_count\", \"video_share_count\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7R3vKUhEb8_"
   },
   "source": [
    "Banned authors' view, like and share counts are much higher than the corresponding counts of active authors' videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyymCn6oFDP3",
    "outputId": "e4268ae0-a8b8-4410-bb33-2829c5cd4540"
   },
   "outputs": [],
   "source": [
    "# Create three new columns to help better understand engagement rates\n",
    "\n",
    "# Create a `likes_per_view column` which represents the number of likes divided by the number of views for each video\n",
    "data[\"likes_per_view\"] = data[\"video_like_count\"]/data[\"video_view_count\"]\n",
    "\n",
    "# Create a `comments_per_view column` which represents the number of comments divided by the number of views for each video\n",
    "data[\"comments_per_view\"] = data[\"video_comment_count\"]/data[\"video_view_count\"]\n",
    "\n",
    "# Create a `shares_per_view column` which represents the number of shares divided by the number of views for each video\n",
    "data[\"shares_per_view\"] = data[\"video_share_count\"]/data[\"video_view_count\"]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZoK3_-bFPW2",
    "outputId": "7fddef17-d3b1-42f8-e656-c0f4c2a4991f"
   },
   "outputs": [],
   "source": [
    "# Use `groupby()` to compile the information in each of the three newly created columns for each combination of categories of claim status and author ban status, then use `agg()` to calculate the count, the mean, and the median of each group\n",
    "statistics_claim_status = data.groupby([\"claim_status\", \"author_ban_status\"]).agg({\"likes_per_view\": [\"count\", \"mean\", \"median\"], \"comments_per_view\": [\"count\", \"mean\", \"median\"], \"shares_per_view\": [\"count\", \"mean\", \"median\"]})\n",
    "\n",
    "# statistics_claim_status\n",
    "statistics_claim_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLhoV4xDFp_o"
   },
   "source": [
    "Averages on data for claim videos are higher in each group (of views, comments, likes and shares) compared to the opinion videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2b.2 Assess data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2c.2 Select visualization type(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tF_82VLgzrQm"
   },
   "source": [
    "# Basic part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paCe: Construct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build visualizations (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select data visualization types that will help you understand and explain the data.\n",
    "\n",
    "Now that you know which data columns you’ll use, it is time to decide which data visualization makes the most sense for EDA of the TikTok dataset. What type of data visualization(s) would be most helpful? Consider the distribution of the data.\n",
    "\n",
    "* Line graph\n",
    "* Bar chart\n",
    "* Box plot\n",
    "* Histogram\n",
    "* Heat map\n",
    "* Scatter plot\n",
    "* A geographic map\n",
    "\n",
    "- ***Box plot to see the distribution of data. It will also be later useful as they also reveal outliers, etc.*** \n",
    "- ***Scatter pilot to see 2 numerical variable relationships, such as \"Views and Likes\".***\n",
    "- ***Histograms to see counts for categorical variables*** \n",
    "- ***Pie chart to see counts between 2 (or a few at max.) variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### video_duration_sec\n",
    "# Create a boxplot to visualize distribution of `video_duration_sec`\n",
    "# Create the boxplot\n",
    "sns.boxplot(data=data, x=\"video_duration_sec\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Video Duration (seconds)\")\n",
    "plt.title(\"Boxplot of Video Duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the values in the `video_duration_sec` column to further explore the distribution of this variable\n",
    "sns.histplot(data=data, x=\"video_duration_sec\", bins=10)\n",
    "plt.xlabel(\"Video Duration (sec)\")\n",
    "plt.title(\"Histogram of Video Duration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video upper limit is 60 sec and the min. length is 5 sec. It is evenly distributed (The distribution is uniform)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### video_view_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_view_count`\n",
    "# Create the boxplot\n",
    "sns.boxplot(data=data, x=\"video_view_count\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Video View Count\")\n",
    "plt.title(\"Boxplot of Video View Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the values in the video_view_count column to further explore the distribution of this variable\n",
    "# Create the histogram\n",
    "sns.histplot(data=data, x=\"video_view_count\", bins=10)\n",
    "plt.xlabel(\"Video View Count\")\n",
    "plt.title(\"Histogram of Video View Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A huge stack (unevenness) is visible on the left side of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### video_like_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot to examine the spread of values in the `video_like_count` column\n",
    "### YOUR CODE HERE ###\n",
    "sns.boxplot(data = data, x =\"video_like_count\")\n",
    "plt.title(\"Video Like Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the values in the video_like_count column to further explore the distribution of this variable\n",
    "sns.histplot(data = data, x=\"video_like_count\", bins =10)\n",
    "plt.xlabel(\"Video Like Count\")\n",
    "plt.title(\"Histogram of Video Like Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is also unevenly distributed significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### video_comment_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_comment_count`\n",
    "sns.boxplot(data = data, x=\"video_comment_count\")\n",
    "plt.title(\"Video Comment Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the values in the video_comment_count column to further explore the distribution of this variable`\n",
    "sns.histplot(data = data, x = \"video_comment_count\", bins = 25)\n",
    "plt.xlabel(\"Video Comment Count\")\n",
    "plt.title(\"Histogtram of Video Comment Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is again highly uneven distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### video_share_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_share_count`\n",
    "sns.boxplot(data = data, x=\"video_share_count\")\n",
    "plt.title(\"Video Share Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the values in the video_share_count column to further explore the distribution of this variable.\n",
    "sns.histplot(data = data, x=\"video_share_count\", bins = 25)\n",
    "plt.xlabel(\"Video Share Count\")\n",
    "plt.title(\"Histogram of Video Share Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unevenly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### video_download_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_download_count`\n",
    "sns.boxplot(data = data, x=\"video_download_count\")\n",
    "plt.title(\"Video Download Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the values in the video_download_count column to further explore the distribution of this variable\n",
    "sns.histplot(data = data, x=\"video_download_count\", bins = 25)\n",
    "plt.xlabel(\"Video Download Count\")\n",
    "plt.title(\"Histogram of Video Download Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is skewed to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMHV86A6zrQo"
   },
   "source": [
    "## pacE: Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3HxcMZgz6iW"
   },
   "source": [
    "### Outcomes\n",
    "- Almost 50% of the videos are claims.\n",
    "- There is a high positive correlation of the banned and under review videos with the claim status videos.\n",
    "- Banned authors' videos have a higher engagement level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Claim status by verification status**\n",
    "Now, create a histogram with four bars: one for each combination of claim status and verification status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram with four bars: one for each combination of claim status and verification status.\n",
    "sns.histplot(data = data, \n",
    "            x=\"claim_status\", \n",
    "            hue = \"verified_status\",\n",
    "            multiple = \"dodge\")\n",
    "plt.title(\"Histogram for Claims by Verification Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unverified users are much higher than verified users and verified users tho post opinions are higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Claim status by author ban status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a histogram, using `groupby()` to examine the count of each claim status fpr each author ban status\n",
    "sns.histplot(data = data, \n",
    "            x = \"claim_status\", \n",
    "            hue = \"author_ban_status\",\n",
    "            hue_order =[\"active\", \"under review\", \"banned\"],\n",
    "            multiple = \"dodge\", \n",
    "            shrink = 0.9)\n",
    "plt.title(\"Histogram for Claim Status by Author Ban Status Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more active authors who post opinions and active users are much higher compared to under_review and banned authors in both claims and opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median view counts by ban status\n",
    "Create a bar plot with three bars: one for each author ban status. The height of each bar should correspond with the median number of views for all videos with that author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a bar plot with three bars: one for each author ban status\n",
    "ban_status_counts = data.groupby([\"author_ban_status\"]).median(numeric_only=True).reset_index()\n",
    "\n",
    "sns.barplot(data = ban_status_counts, \n",
    "            x = \"author_ban_status\", \n",
    "            y = \"video_view_count\", \n",
    "            order = [\"active\", \"under review\", \"banned\"])\n",
    "plt.title(\"Median View Counts by Ban Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under review and banned accounts (non-active accounts) have a very high count of median views.\n",
    "\n",
    "Important outcome: `video_view_count` might be good indicator of claim status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median view count for claim status\n",
    "data.groupby(\"claim_status\")[\"video_view_count\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#### Total views by claim status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie graph that depicts the proportions of total views for clain videos and total views for opinion videos\n",
    "plt.pie(data.groupby(\"claim_status\")[\"video_view_count\"].sum(), labels=[\"claim\", \"opinion\"])\n",
    "plt.title(\"Total Views by Claim Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 4. Determine outliers**\n",
    "\n",
    "When building predictive models, the presence of outliers can be problematic. For example, if you were trying to predict the view count of a particular video, videos with extremely high view counts might introduce bias to a model. Also, some outliers might indicate problems with how data was captured or recorded.\n",
    "\n",
    "The ultimate objective of the TikTok project is to build a model that predicts whether a video is a claim or opinion. The analysis you've performed indicates that a video's engagement level is strongly correlated with its claim status. There's no reason to believe that any of the values in the TikTok data are erroneously captured, and they align with expectation of how social media works: a very small proportion of videos get super high engagement levels. That's the nature of viral content.\n",
    "\n",
    "Nonetheless, it's good practice to get a sense of just how many of your data points could be considered outliers. The definition of an outlier can change based on the details of your project, and it helps to have domain expertise to decide a threshold. You've learned that a common way to determine outliers in a normal distribution is to calculate the interquartile range (IQR) and set a threshold that is 1.5 * IQR above the 3rd quartile.\n",
    "\n",
    "In this TikTok dataset, the values for the count variables are not normally distributed. They are heavily skewed to the right. One way of modifying the outlier threshold is by calculating the **median** value for each variable and then adding 1.5 * IQR. This results in a threshold that is, in this case, much lower than it would be if you used the 3rd quartile.\n",
    "\n",
    "Write a for loop that iterates over the column names of each count variable. For each iteration:\n",
    "1. Calculate the IQR of the column\n",
    "2. Calculate the median of the column\n",
    "3. Calculate the outlier threshold (median + 1.5 * IQR)\n",
    "4. Calculate the numer of videos with a count in that column that exceeds the outlier threshold\n",
    "5. Print \"Number of outliers, {column name}: {outlier count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "columns = [\"video_view_count\", \n",
    "           \"video_like_count\", \n",
    "           \"video_share_count\", \n",
    "           \"video_download_count\",\n",
    "           \"video_comment_count\",\n",
    "           ]\n",
    "\n",
    "for column in columns: \n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)\n",
    "    iqr = q3 - q1 \n",
    "    outlier_threshold = data[column].median() + 1.5*iqr\n",
    "    \n",
    "    outlier_count = (data[column] > outlier_threshold).sum()\n",
    "    print(f\"Number of outliers, {column}:\", outlier_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot of `video_view_count` versus `video_like_count` according to 'claim_status'\n",
    "sns.scatterplot(data = data, x = \"video_view_count\", \n",
    "                y = \"video_like_count\", \n",
    "                hue = \"claim_status\", \n",
    "                s = 5, \n",
    "                alpha = 0.5)\n",
    "plt.title(\"Video View Count vs. Video Like Count acc. to Claim Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot of `video_view_count` versus `video_like_count` for opinions only\n",
    "sns.scatterplot(data = data, x = \"video_view_count\", \n",
    "                y = \"video_like_count\", \n",
    "                hue = \"claim_status\" == \"opinion\", \n",
    "                s = 5, \n",
    "                alpha = 0.5)\n",
    "plt.title(\"Video View Count vs. Video Like Count for 'opinion' Claims\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PACE: Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 5a. Results and evaluation**\n",
    "\n",
    "Having built visualizations in Tableau and in Python, what have you learned about the dataset? What other questions have your visualizations uncovered that you should pursue?\n",
    "\n",
    "***Pro tip:*** Put yourself in your client's perspective, what would they want to know?\n",
    "\n",
    "Use the following code cells to pursue any additional EDA. Also use the space to make sure your visualizations are clean, easily understandable, and accessible.\n",
    "\n",
    "***Ask yourself:*** Did you consider color, contrast, emphasis, and labeling?\n",
    "\n",
    "I have learned .... that visualization is a very strong method to quickly review distribution of the data point and some patterns in order to inspect in details later. It was possible to reveal that the claim videos have interesting engagement levels.\n",
    "\n",
    "My other questions are .... if the claim videos have a pattern in their video_transcription text.\n",
    "\n",
    "My client would likely want to know ... if it would be possible to detect any patterns to identify claim videos other than the counts, and would also like to make sure to avoid false positives in order not to make a displeasent user experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5b. Conclusion\n",
    "*Make it professional and presentable*\n",
    "\n",
    "You have visualized the data you need to share with the director now. Remember, the goal of a data visualization is for an audience member to glean the information on the chart in mere seconds.\n",
    "\n",
    "*Questions to ask yourself for reflection:*\n",
    "Why is it important to conduct Exploratory Data Analysis? What other visuals could you create?\n",
    "\n",
    "EDA is important because ...\n",
    "it guides what to focus on for analysis and to prepare for future modeling.\n",
    "\n",
    "Visualizations helped me understand ..\n",
    "the (unusual) patterns which need to be inspected, conveniently and that the data is not yet ready for the next steps as the outliers, missing data, etc all need to be handled first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to conduct a two-sample t-test. \n",
    "\n",
    "Steps for conducting a hypothesis test:\n",
    "\n",
    "1.   State the null hypothesis and the alternative hypothesis\n",
    "2.   Choose a signficance level\n",
    "3.   Find the p-value\n",
    "4.   Reject or fail to reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ß0 = there is no difference between the video view counts of verified users and not verified users (any difference between the two is by chance)\n",
    "ß1 = `video_view_count` of not verified users are higher (any difference between the two is actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significance level: 5% is chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a two-sample t-test to compare means\n",
    "verified_views = data[data[\"verified_status\"] == \"verified\"][\"video_view_count\"]\n",
    "not_verified_views = data[data[\"verified_status\"] == \"not verified\"][\"video_view_count\"]\n",
    "\n",
    "stats.ttest_ind(a=not_verified_views, b=verified_views, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is 2.61, which is very small, therefore the null hypothesis is rejected. The difference between the video view counts of \"verified\" accounts and \"not verified\" accounts are not by random chance and statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PACE: Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Communicate insights with stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome\n",
    "The video view counts acc. to the user verified status is statistically significant, in which the not verified accounts have a very high amount. It should be investigated further. It is required to build a regression model in the next step. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
